coord_flip() +
theme_bw()
T17 #open up a new script run trigram, and save as pdf!
########################################################################################
########################################################################################
########################################################################################
trainWords <- scripts %>% #I might use scripts2 here
count_bigrams()
write.csv(trainWords, file = "C:\\Users/coyle/OneDrive/Documents/trainWordsbi.csv")
P18<-trainWords %>%
#adjust filters for graphic
filter(n > 5,
!str_detect(word1, "\\d"),
!str_detect(word2, "\\d")) %>%
visualize_bigrams()
P18
trainWords <- scripts %>% #I might use scripts2 here
count_bigrams()
write.csv(trainWords, file = "C:\\Users/coyle/OneDrive/Documents/trainWordsbi.csv")
P18B<-trainWords %>%
#adjust filters for graphic
filter(n > 6, #could remove comma and delete two lines if needed...
#if the nodes do not all fit, decrease the number for the filter
!str_detect(word1, "\\d"), #don't have to have this line
!str_detect(word2, "\\d")) %>% #don't have to have this line
visualize_bigrams()
P18B
count_trigrams <- function(dataset) {
dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 3) %>%
separate(bigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE)
}
visualize_trigrams <- function(trigrams) {
set.seed(2016)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
trigrams %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
}
########################################################################################
########################################################################################
########################################################################################
########################################################################################
trainWords <- scripts %>% #I might use scripts2 here
count_trigrams()
write.csv(trainWords, file = "C:\\Users/coyle/OneDrive/Documents/trainWordstri.csv")
P19<-trainWords %>%
#adjust filters for graphic
filter(n > 6) %>%
visualize_trigrams()
P19
trainWords <- scripts %>% #I might use scripts2 here
count_trigrams()
write.csv(trainWords, file = "C:\\Users/coyle/OneDrive/Documents/trainWordstri.csv")
P19B<-trainWords %>%
#adjust filters for graphic
filter(n > 5) %>%
visualize_trigrams()
P19B
unigram_probs <- scripts %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
mutate(p = n / sum(n))
unigram_probs
write.csv(unigram_probs, file = "C:\\Users/coyle/OneDrive/Documents/unigram_probs.csv")
#########################################################################################
library(textdata)
#the original code had a file address that was no longer working, so I had to setup a manual
#download of the affin value table
textdata::lexicon_afinn(manual_download = TRUE) #will show where to move file if downloaded manually
#then on the bash terminal I "mv /downloaded path/ /textdata retrieval path/
#mv /mnt/c/Users/coyle/Downloads/imm6010.zip /mnt/c/Users/coyle/AppData/Local/textdata/textdata/Cache/afinn/
positiveWordsBarGraph <- function(SC) {
#afinn_list <- read.delim(file='C:\\Users/coyle/OneDrive/Documents/R_Work_Board_2020/AFINN/AFINN-111.txt', header=FALSE, stringsAsFactors=FALSE)
contributions <- SC %>%
unnest_tokens(word, text) %>%
count(Character, word, sort = TRUE) %>%
ungroup() %>%
#    inner_join(get_sentiments("C:\\Users/coyle/OneDrive/Documents/R_Work_Board_2020/AFINN/AFINN-111.txt"), by = "word") %>%
#inner_join(affin_list, by = "word") %>%
inner_join(get_sentiments("afinn"), by = "word") %>%
group_by(word) %>%
summarize(occurences = n(),
# contribution = sum(score))
contribution = sum(value)) #the column nane switched from score to value
#with updated affin document
contributions %>%
top_n(20, abs(contribution)) %>%
mutate(word = reorder(word, contribution)) %>%
head(20) %>%
ggplot(aes(word, contribution, fill = contribution > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() + theme_bw()
}
P21<-positiveWordsBarGraph(scripts)
P21
# function to get & plot the most informative terms by a specificed number
# of topics, using LDA
top_terms_by_topic_LDA <- function(input_text, # should be a columm from a dataframe
plot = T, # return a plot? TRUE by defult
number_of_topics = 4) # number of topics (4 by default)
{
# create a corpus (type of object expected by tm) and document term matrix
Corpus <- Corpus(VectorSource(input_text)) # make a corpus object
DTM <- DocumentTermMatrix(Corpus) # get the count of words/document
# remove any empty rows in our document term matrix (if there are any
# we'll get an error when we try to run our LDA)
unique_indexes <- unique(DTM$i) # get the index of each unique value
DTM <- DTM[unique_indexes,] # get a subset of only those indexes
# preform LDA & get the words/topic in a tidy text format
lda <- LDA(DTM, k = number_of_topics, control = list(seed = 1234))
topics <- tidy(lda, matrix = "beta")
# get the top ten terms for each topic
top_terms <- topics  %>% # take the topics data frame and..
group_by(topic) %>% # treat each topic as a different group
top_n(10, beta) %>% # get the top 10 most informative words
ungroup() %>% # ungroup
arrange(topic, -beta) # arrange words in descending informativeness
# if the user asks for a plot (TRUE by default)
if(plot == T){
# plot the top ten terms for each topic in order
top_terms %>% # take the top terms
mutate(term = reorder(term, beta)) %>% # sort terms by beta value
ggplot(aes(term, beta, fill = factor(topic))) + # plot beta by theme
geom_col(show.legend = FALSE) + # as a bar plot
facet_wrap(~ topic, scales = "free") + # which each topic in a seperate plot
labs(x = NULL, y = "Beta") + # no x label, change y label
coord_flip() # turn bars sideways
}else{
# if the user does not request a plot
# return a list of sorted terms instead
return(top_terms)
}
}
create_LDA_topics <- function(business_text,custom_stop_words)
{
# create a document term matrix to clean
reviewsCorpus <- Corpus(VectorSource(business_text$text))
reviewsDTM <- DocumentTermMatrix(reviewsCorpus)
# convert the document term matrix to a tidytext corpus
reviewsDTM_tidy <- tidy(reviewsDTM)
# remove stopwords
reviewsDTM_tidy_cleaned <- reviewsDTM_tidy %>% # take our tidy dtm and...
anti_join(stop_words, by = c("term" = "word")) %>% # remove English stopwords and...
anti_join(custom_stop_words, by = c("term" = "word")) # remove my custom stopwords
top_terms_by_topic_LDA(reviewsDTM_tidy_cleaned$term, number_of_topics = 4)
}
custom_stop_words <- tibble(word = c("yeah","hey","gotta","uh"))
P28<-create_LDA_topics(scripts,custom_stop_words)
P28
########################################################################################
#For Corpuses###########################################################################
###########################Supervised Learning: Variable Importance#####################
########################################################################################
makeDTM <- function(train) {
corpus = Corpus(VectorSource(train$text))
# Pre-process data
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
# Remove sparse terms
dtm = removeSparseTerms(dtm, 0.997)
# Create data frame
labeledTerms = as.data.frame(as.matrix(dtm))
return(labeledTerms)
}
makeFeatures <- function(train) {
labeledTerms = makeDTM(train)
## Preparing the features for the XGBoost Model
features <- colnames(labeledTerms)
for (f in features) {
if ((class(labeledTerms[[f]])=="factor") || (class(labeledTerms[[f]])=="character")) {
levels <- unique(labeledTerms[[f]])
labeledTerms[[f]] <- as.numeric(factor(labeledTerms[[f]], levels=levels))
}
}
return(labeledTerms)
}
scriptsTopTenCharacters = scripts %>%
filter(Character %in% Top10Characters$Character)
labeledTerms = makeFeatures(scriptsTopTenCharacters)
labeledTerms$Character = as.factor(scriptsTopTenCharacters$Character)
levels(labeledTerms$Character) = make.names(unique(labeledTerms$Character))
formula = Character ~ .
fitControl <- trainControl(method="none",classProbs=TRUE, summaryFunction=mnLogLoss)
#If Error: One or more factor levels in the outcome has no data: 'X10'
#Change classProbs=FALSE, The Error will occur after runing CharacterXGB
#As others pointed out earlier, this problem only occurs when classProbs=TRUE which
#causes the train function to generate additional statistics related to the outcome class
xgbGrid <- expand.grid(nrounds = 10,
max_depth = 3,
eta = .05,
gamma = 0,
colsample_bytree = .8,
min_child_weight = 1,
subsample = 1)
set.seed(13)
CharacterXGB = train(formula, data = labeledTerms,
method = "xgbTree",trControl = fitControl,
tuneGrid = xgbGrid,na.action = na.pass,metric="LogLoss", maximize=FALSE)
#######
importance = varImp(CharacterXGB)
varImportance <- data.frame(Variables = row.names(importance[[1]]),
Importance = round(importance[[1]]$Overall,2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance)))) %>%
head(20)
rankImportancefull = rankImportance
P29<-ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance)) +
geom_bar(stat='identity',colour="white", fill = fillColor) +
geom_text(aes(x = Variables, y = 1, label = Rank),
hjust=0, vjust=.5, size = 4, colour = 'black',
fontface = 'bold') +
labs(x = 'Variables', title = 'Relative Variable Importance') +
coord_flip() +
theme_bw()
P29
######
importance = varImp(CharacterXGB)
varImportance <- data.frame(Variables = row.names(importance[[1]]),
Importance = round(importance[[1]]$Overall,2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance)))) %>%
head(50)
rankImportancefull = rankImportance
T29<-ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance)) +
geom_bar(stat='identity',colour="white", fill = fillColor) +
geom_text(aes(x = Variables, y = 1, label = Rank),
hjust=0, vjust=.5, size = 4, colour = 'black',
fontface = 'bold') +
labs(x = 'Variables', title = 'Relative Variable Importance') +
coord_flip() +
theme_bw()
T29
#######################################################################################
#Could use this as the basis of another concordance for network
#######################################################################################
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance)))) %>%
head(10000)
write.csv(rankImportancefull, file = "C:\\Users/coyle/OneDrive/Documents/rankImportancefull.csv")
pdf(file = "C:\\Users/coyle/OneDrive/Documents/TRIANGULATION1.pdf", paper = "USr", title="if you want any")
#P1
T1
#P2
#P3
T3
P15
#T15
#P16
T16
#P17
T17
P21
P28
#P29
T29
dev.off()
pdf(file = "C:\\Users/coyle/OneDrive/Documents/TRAJECTORY.pdf", paper = "USr", title="if you want any")
P18
P18B
P19
dev.off()
######################################################################33
##########NETWORKS
png('C:\\Users/coyle/OneDrive/Documents/108.png', width = 1400, height = 720)
P18
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/109.png', width = 1400, height = 720)
P18B
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/110.png', width = 1400, height = 720)
P19
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/111.png', width = 1400, height = 720)
P19B
dev.off()
#############################
##############################
#orginally width = 1920, height = 1080, font was too small
png('C:\\Users/coyle/OneDrive/Documents/100.png', width = 1400, height = 720)
T1
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/101.png', width = 1400, height = 720)
T3
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/102.png', width = 1400, height = 720)
P15
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/103.png', width = 1400, height = 720)
T16
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/104.png', width = 1400, height = 720)
T17
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/105.png', width = 1400, height = 720)
P21
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/106.png', width = 1400, height = 720)
P28
dev.off()
png('C:\\Users/coyle/OneDrive/Documents/107.png', width = 1400, height = 720)
T29
dev.off()
#svg('C:\\Users/GRC/Documents/100.svg', width = 1400, height = 720)
#svg('C:\\Users/GRC/Documents/100.svg', width = 1400, height = 720)
#T1
#STEP 1: LOAD THE DATA
#load the data
library(tidyverse)
#letters <- read_csv("/Users/GRC/Documents/R_Work_Board_DEC_2018/1-R_STRUCTURED/5-NETWORKS_GEOCODE_PLOTLY/Data/Input/trainWordsbi_reduced.csv")
letters <- read_csv("C:\\Users/coyle/OneDrive/Documents/WAL_BW.csv")
#letters <- read_csv("/Users/GRC/Documents/desired_sort_filter.csv")
#letters <- read_csv("./  Data/Input/Node_List_Practice_Letters_of_Author.csv")
#look at the data
letters #vertical view
letters %>% glimpse() #horizotal view
sources <- letters %>%
distinct(source) %>%
rename(label = source)
sources
destinations <- letters %>%
distinct(destination) %>%
rename(label = destination)
destinations
nodes <- full_join(sources, destinations, by = "label")
nodes
nodes <- nodes %>% rowid_to_column("id")
nodes
per_route <- letters %>%
group_by(source, destination) %>%
summarise(weight = n()) %>%
ungroup()
per_route
edges <- per_route %>%
left_join(nodes, by = c("source" = "label")) %>%
rename(from = id)
edges <- edges %>%
left_join(nodes, by = c("destination" = "label")) %>%
rename(to = id)
edges
edges <- select(edges, from, to, weight)
edges
library(visNetwork)
library(networkD3)
N0<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visOptions(selectedBy = "label",
highlightNearest = TRUE,
nodesIdSelection = FALSE) %>%
visPhysics(stabilization = FALSE)
##############################
library(htmlwidgets)
saveWidget(N0, file="N0_menu.html")
#!! 1:  Dynamic, No Selection, Highlight nearest,
N1<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visOptions( highlightNearest = TRUE,
nodesIdSelection = FALSE) %>%
visPhysics(stabilization = FALSE)
##############################
#library(htmlwidgets)
saveWidget(N1, file="N1_DH.html")
#!! 2: Dynamic, No Selection, Do Not Highlight Nearest
N2<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visOptions( highlightNearest = FALSE,
nodesIdSelection = FALSE) %>%
visPhysics(stabilization = FALSE)
##############################
#library(htmlwidgets)
saveWidget(N2, file="N2_DNH.html")
#3: custom navigation
N3<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visOptions( highlightNearest = FALSE,
nodesIdSelection = FALSE) %>%
visPhysics(stabilization = FALSE)%>%
visInteraction(navigationButtons = TRUE)
##############################
#library(htmlwidgets)
saveWidget(N3, file="N3.html")
#!! 4: hierarchical #Useful, shows a layering of information
N4<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visHierarchicalLayout()%>%
visPhysics(stabilization = FALSE)%>%
visOptions(selectedBy = "label",
highlightNearest = TRUE,
nodesIdSelection = FALSE)
##############################
#library(htmlwidgets)
saveWidget(N4, file="N4_H.html")
#5: static
#again very useful
N5<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visIgraphLayout(layout = "layout_with_fr")
#visEdges(arrows = "middle")
##############################
#library(htmlwidgets)
saveWidget(N5, file="N5.html")
#!! 6: Static layout nicely
N6<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visIgraphLayout(layout="layout_nicely")%>%
visPhysics(stabilization = FALSE)
##############################
#library(htmlwidgets)
saveWidget(N6, file="N6_ST.html")
#!! 7: Static Layout circle: Wow!
N7<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visIgraphLayout(layout="layout_in_circle")%>%
visPhysics(stabilization = FALSE)%>%
visOptions(selectedBy = "label",
highlightNearest = TRUE,
nodesIdSelection = FALSE)
##############################
#library(htmlwidgets)
saveWidget(N7, file="N7_C.html")
#8: Quick Dynamic
N8<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visIgraphLayout(physics = TRUE, smooth = TRUE)%>%
visPhysics(stabilization = FALSE)
##############################
#library(htmlwidgets)
saveWidget(N8, file="N8.html")
#!! 9: Sugiyama: Layering 2
N9<-visNetwork(nodes, edges, height = "700px", width = "100%") %>%
visIgraphLayout(layout = "layout_with_sugiyama")%>%
visPhysics(stabilization = FALSE)%>%
visOptions(selectedBy = "label",
highlightNearest = TRUE,
nodesIdSelection = FALSE)
##############################
#library(htmlwidgets)
saveWidget(N9, file="N9_Sug.html")
edges <- mutate(edges, width = weight/5 + 1)
N10<-visNetwork(nodes, edges, height = "1000px", width = "100%") %>%
visIgraphLayout(layout = "layout_with_fr") %>%
visEdges(arrows = "middle")
##############################
#library(htmlwidgets)
saveWidget(N10, file="N10_ARROW.html")
nodes_d3 <- mutate(nodes, id = id - 1)
edges_d3 <- mutate(edges, from = from - 1, to = to - 1)
#WOW!!!!!!!!!!!!!!!!!!!!!!!!!!!
N11<-forceNetwork(Links = edges_d3, Nodes = nodes_d3, Source = "from", Target = "to",
NodeID = "label", Group = "id", Value = "weight",
opacity = 1, fontSize = 16, zoom = TRUE)
##############################
#library(htmlwidgets)
saveWidget(N11, file="N11_Disp.html")
#library(networkD3)
xx<-sankeyNetwork(Links = edges_d3, Nodes = nodes_d3, Source = "from", Target = "to",
NodeID = "label", Value = "weight", fontSize = 16, unit = "Letter(s)")
links<-edges#note switching edges to links to signal a different strategy
library("igraph")
#net <- graph_from_data_frame(d=links, vertices=nodes, directed=T)
net <- graph_from_data_frame(d=links, vertices=nodes, directed=T) #, directed=T)
net2 <- simplify(net)
V(net2)$color <- ifelse(V(net2)$Q1_I1 == 1, "lightblue", "orange")
plot(net2)
#links <- read.csv("Data/Input/Data files/Dataset1-Media-Example-EDGES.csv", header=T, as.is=T)
library("threejs")
library("htmlwidgets")
net.js <- net
graph_attr(net.js, "layout") <- NULL
#bg is background
gjs <- graphjs(vertex.size = .5, vertex.color="black", edge.color = "red",
net.js, main="", bg="blue", showLabels=T, stroke=F,
curvature=0.1, attraction=.9, repulsion=1, opacity=.2)
#Works but cannot see until I send to browswer with browseURL function 3 steps below
gjs
#saveWidget(gjs, file="Media-Network-gjs.html")
#browseURL("Media-Network-gjs.html")
saveWidget(gjs, file="C:\\Users/coyle/OneDrive/Documents/N12_EE.html")
#HAVEN'T used this much vs graph above
gjs.an <- graphjs(net.js, bg="gray10", showLabels=F, stroke=F,
layout=list(layout_randomly(net.js, dim=3),
layout_with_fr(net.js,  dim=3),
layout_with_drl(net.js, dim=3),
layout_on_sphere(net.js)),
vertex.color=list(V(net.js)$color, "gray", "black",
V(net.js)$color),
main=list("Random Layout", "Fruchterman-Reingold",
"DrL layout", "Sphere" ) )
print(gjs.an)
saveWidget(gjs.an, file="C://Users/GRC/Documents/NETWORK_Electric_Edge.html")
#browseURL("Media-Network-gjs-an.html")
browseURL("C://Users/GRC/Documents/NETWORK_Electric_Edge.html")
#dynamic Arrow
visNetwork(nodes, edges) %>% visEdges(arrows = "to") %>%
visOptions(collapse = TRUE)
#abspath <- function(files)file.path(normalizePath(dirname(files)), files)
#setwd("~/gcoyle1.github.io/1-2022/Valmiki_Sanskrit_Epics_IM/")
setwd("~/gcoyle1.github.io/1-2022/Walmart_Emails_2022_1/")
inputFile<-list.files()
#abspath(files)
outputFile = paste(normalizePath(dirname(inputFile)),"\\", inputFile,  sep = "")
outputFile
#list.files(pattern='\\.html', recursive=TRUE)
x<-as.data.frame(outputFile)
library(readr)
write_delim(x, path = "C:\\Users\\coyle\\OneDrive\\Documents\\path.txt", delim = ",")
